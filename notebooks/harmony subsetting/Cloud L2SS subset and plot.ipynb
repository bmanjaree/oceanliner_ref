{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Level 2 Subsetter (L2SS) API \n",
    "This will demonstrate how to subset swath/L2 data with the data and services hosted on the cloud. Uses single granule subsetting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start (UAT login)\n",
    "Before you begin this tutorial, make sure you have an account in the Earthdata Login UAT environment, which \n",
    "will be used for this notebook by visiting [https://uat.urs.earthdata.nasa.gov](https://uat.urs.earthdata.nasa.gov).\n",
    "These accounts, as all Earthdata Login accounts, are free to create and only take a moment to set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Authentication\n",
    "\n",
    "We need some boilerplate up front to log in to Earthdata Login.  The function below will allow Python\n",
    "scripts to log into any Earthdata Login application programmatically.  To avoid being prompted for\n",
    "credentials every time you run and also allow clients such as curl to log in, you can add the following\n",
    "to a `.netrc` (`_netrc` on Windows) file in your home directory:\n",
    "\n",
    "```\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login <your username>\n",
    "    password <your password>\n",
    "```\n",
    "\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating\n",
    "\"netrc access too permissive.\"\n",
    "\n",
    "`$ chmod 0600 ~/.netrc` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "import getpass\n",
    "import netrc\n",
    "\n",
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT (Harmony's current default)\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    try:\n",
    "        username, _, password = netrc.netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        password = getpass.getpass()\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the above function to set up Earthdata Login for subsequent requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_earthdata_login_auth('uat.urs.earthdata.nasa.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a granule for subsetting\n",
    "\n",
    "Below we call out a specific file/granule on which we will use the podaac L2 subsetter. Finding this information would complicate the tutorial, but there are several other demos that show how to use the search APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Subset of a PO.DAAC Granule\n",
    "\n",
    "We can now build onto the root URL in order to actually perform a transformation.  The first transformation is a subset of a selected granule.  _At this time, this requires discovering the granule id from CMR_.  That information can then be appended to the root URL and used to call Harmony with the help of the `request` library.\n",
    "\n",
    "Above we show how to find a granule id for processing.\n",
    "\n",
    "**Notes:**\n",
    "  The L2 subsetter current streams the data back to the user, and does not stage data in S3 for redirects. This is functionality we will be adding over time.\n",
    "  It doesn't work with URS backed files, which is coming in the next few weeks\n",
    "  it only works on the show dataset, but \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bblat_max=60\n",
    "bblat_min=0\n",
    "bblon_max=180\n",
    "bblon_min=-180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_root = 'https://harmony.uat.earthdata.nasa.gov'\n",
    "bboxSubsetConfig = {\n",
    "    'collection_id': 'C1234208437-POCLOUD',  #Jason-1 GDR SSHA version E NetCDF    \n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleid': 'G1234311525-POCLOUD',      #JA1_GPR_2PeP001_092_20020118_182623_20020118_192236.nc\n",
    "    'lat': '(' + str(bblat_min) + ':' + str(bblat_max) + ')',\n",
    "    'lon': '(' + str(bblon_min) + ':' + str(bblon_max) + ')'\n",
    "}\n",
    "\n",
    "bbox_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?granuleid={granuleid}&subset=lat{lat}&subset=lon{lon}'.format(**bboxSubsetConfig)\n",
    "print('Request URL', bbox_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "with request.urlopen(bbox_url) as response, open('ogc_temp.nc', 'wb') as out_file:\n",
    "    print('Content Size:', response.headers['Content-length'])\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "    print(\"Downloaded request to ogc_temp.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xa\n",
    "ds = xa.open_dataset('ogc_temp.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "ds.ssha.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the subsetting worked\n",
    "\n",
    "Bounds are defined earlier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lat_max = ds.lat.max()\n",
    "lat_min = ds.lat.min()\n",
    "\n",
    "lon_min = ds.lon.min()\n",
    "lon_max = ds.lon.max()\n",
    "\n",
    "\n",
    "if lat_max < bblat_max and lat_min > bblat_min:\n",
    "    print(\"Successful Latitude subsetting\")\n",
    "else:\n",
    "    assert false\n",
    "\n",
    "    \n",
    "if lon_max < bblon_max and lon_min > bblon_min:\n",
    "    print(\"Successful Longitude subsetting\")\n",
    "else:\n",
    "    assert false\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot swath onto a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(ds.lon, ds.lat, lw=2, c=ds.ssha)\n",
    "plt.colorbar()\n",
    "plt.clim(-0.3, 0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
