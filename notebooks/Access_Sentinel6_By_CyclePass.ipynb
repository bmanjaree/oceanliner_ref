{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Before-you-start\" data-toc-modified-id=\"Before-you-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Before you start</a></span></li><li><span><a href=\"#Authentication-setup\" data-toc-modified-id=\"Authentication-setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Authentication setup</a></span></li><li><span><a href=\"#Hands-off-workflow\" data-toc-modified-id=\"Hands-off-workflow-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hands-off workflow</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Sentinel-6 NRT Data\n",
    "\n",
    "This notebook shows a simple way to maintain a local time series of [Sentinel-6](#) NRT data using the [CMR Search API](#). It downloads granules the ingested since the previous run to a designated data folder and overwrites a hidden file inside with the timestamp of the CMR Search request on success.\n",
    "\n",
    "> User note: The notebook actually points to a MODIS SST collection for now ([10.5067/GHMDA-2PJ19](https://doi.org/10.5067/GHMDA-2PJ19). It'll work just the same for Sentinel-6.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "Before you beginning this tutorial, make sure you have an Earthdata account [https://uat.urs.earthdata.nasa.gov](https://uat.urs.earthdata.nasa.gov).\n",
    "\n",
    "Accounts are free to create and take just a moment to set up.\n",
    "\n",
    "## Authentication setup\n",
    "\n",
    "*You'll probably need to use the netrc method when running from command line.* \n",
    "\n",
    "We need some boilerplate up front to log in to Earthdata Login.  The function below will allow Python\n",
    "scripts to log into any Earthdata Login application programmatically.  To avoid being prompted for\n",
    "credentials every time you run and also allow clients such as curl to log in, you can add the following\n",
    "to a `.netrc` (`_netrc` on Windows) file in your home directory:\n",
    "\n",
    "```\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login <your username>\n",
    "    password <your password>\n",
    "```\n",
    "\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating\n",
    "\"netrc access too permissive.\"\n",
    "\n",
    "`$ chmod 0600 ~/.netrc` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:35.608841Z",
     "start_time": "2020-08-03T21:34:35.595193Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "import getpass\n",
    "import netrc\n",
    "\n",
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT (Harmony's current default)\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    try:\n",
    "        username, _, password = netrc.netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        password = getpass.getpass()\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:35.977874Z",
     "start_time": "2020-08-03T21:34:35.969827Z"
    }
   },
   "outputs": [],
   "source": [
    "setup_earthdata_login_auth('uat.urs.earthdata.nasa.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-off workflow\n",
    "\n",
    "This workflow/notebook can be run routinely to maintain a time series of NRT data, downloading new granules as they become available in CMR. There are at least a few ways to run it:\n",
    "\n",
    "* from the notebook server, \n",
    "* from the command line with papermill, and\n",
    "* using nbconvert/papermill with a job scheduler like cron.\n",
    "\n",
    "The notebook writes a file `.update` to the target data directory the first time it's run. Every subsequent run that finishes successfully overwrites the file with a new timestamp corresponding to the time used for the  granules search parameter `created_at`.\n",
    "\n",
    "The variables in the cell below determine the workflow behavior in it's initial run. (*`mins` only applies to the first run.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:36.659007Z",
     "start_time": "2020-08-03T21:34:36.655972Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# This cell accepts parameters from command line with papermill: \n",
    "#  https://papermill.readthedocs.io\n",
    "#\n",
    "\n",
    "#mins = 1440  # Limit the results to granules ingested in the last ___ minutes.\n",
    "trackcycle = 230  # Set the cycle and pass numbers to use for the CMR\n",
    "trackpass = 1     # granules search.\n",
    "\n",
    "cmr = \"cmr.uat.earthdata.nasa.gov\"  # The domain for CMR or CMR UAT\n",
    "\n",
    "ccid = \"C1234208437-POCLOUD\"  # The 'concept-id' of the desired CMR collection\n",
    "\n",
    "data = \"resources/cyclepass\"  # The target path for the NRT granules to download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `data` is pointed at a nearby folder [`resources/nrt`](resources/nrt/) by default. **You should change `data` to a suitable download path on your file system.** An unlucky sequence of git commands could disappear that folder and its downloads, if your not careful. Just change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:37.529031Z",
     "start_time": "2020-08-03T21:34:37.525953Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import isdir, basename\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from datetime import datetime, timedelta\n",
    "from json import dumps, loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The search retrieves granules ingested during the last `n` minutes.** A file in your local data dir  file that tracks updates to your data directory, if one file exists. The CMR Search falls back on the ten minute window if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:38.398113Z",
     "start_time": "2020-08-03T21:34:38.395784Z"
    }
   },
   "outputs": [],
   "source": [
    "#timestamp = (datetime.utcnow()-timedelta(minutes=mins)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "#timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will replace the timestamp above with the one read from the `.update` file in the data directory, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:39.138099Z",
     "start_time": "2020-08-03T21:34:39.135792Z"
    }
   },
   "outputs": [],
   "source": [
    "#if not isdir(data):\n",
    "#    print(f\"NOTE: Making new data directory at '{data}'. (This is the first run.)\")\n",
    "#    makedirs(data)\n",
    "#else:\n",
    "#    try:\n",
    "#        with open(f\"{data}/.update\", \"r\") as f:\n",
    "#            timestamp = f.read()\n",
    "#    except FileNotFoundError:\n",
    "#        print(\"WARN: No .update in the data directory. (Is this the first run?)\")\n",
    "#    else:\n",
    "#        print(f\"NOTE: .update found in the data directory. (The last run was at {timestamp}.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to query for CMR updates that occured during a given timeframe. Read on in the CMR Search documentation:\n",
    "\n",
    "* https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#c-with-new-granules (Collections)\n",
    "* https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#c-with-revised-granules (Collections)\n",
    "* https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#g-production-date (Granules)\n",
    "* https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#g-created-at (Granules)\n",
    "\n",
    "The `created_at` parameter works for our purposes. It's a granule search parameter that returns the records ingested since the input timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:40.791107Z",
     "start_time": "2020-08-03T21:34:40.782819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scroll': 'true',\n",
       " 'page_size': 2000,\n",
       " 'sort_key': '-start_date',\n",
       " 'collection_concept_id': 'C1234208437-POCLOUD',\n",
       " 'cycle': 230,\n",
       " 'passes[0][pass]': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'scroll': \"true\",\n",
    "    'page_size': 2000,\n",
    "    'sort_key': \"-start_date\",\n",
    "    'collection_concept_id': ccid, \n",
    "    #'created_at': timestamp,\n",
    "    # Limit results to granules matching cycle, pass numbers:\n",
    "    'cycle': trackcycle,\n",
    "    'passes[0][pass]': trackpass,\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the query parameters as a string and then the complete search url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:34:41.991705Z",
     "start_time": "2020-08-03T21:34:41.988418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cmr.uat.earthdata.nasa.gov/search/granules.umm_json?scroll=true&page_size=2000&sort_key=-start_date&collection_concept_id=C1234208437-POCLOUD&cycle=230&passes%5B0%5D%5Bpass%5D=1\n"
     ]
    }
   ],
   "source": [
    "query = urlencode(params)\n",
    "url = f\"https://{cmr}/search/granules.umm_json?{query}\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the granule records that match our search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:35:18.615787Z",
     "start_time": "2020-08-03T21:35:18.072473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 granules results for 'C1234208437-POCLOUD' cycle '230' and pass '1'.\n"
     ]
    }
   ],
   "source": [
    "with urlopen(url) as f:\n",
    "    results = loads(f.read().decode())\n",
    "\n",
    "print(f\"{results['hits']} granules results for '{ccid}' cycle '{trackcycle}' and pass '{trackpass}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neatly print the first granule's record for reference (assuming at least one was returned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:36:19.888287Z",
     "start_time": "2020-08-03T21:36:19.886488Z"
    }
   },
   "outputs": [],
   "source": [
    "#if len(results['items'])>0:\n",
    "#    print(dumps(results['items'][0], indent=2))\n",
    "#    \n",
    "#    # Also, replace timestamp with one corresponding to time of the search.\n",
    "#    timestamp = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link for http access denoted by `\"Type\": \"GET DATA\"` in the list of `RelatedUrls`.\n",
    "\n",
    "Grab the download URL, but do it in a way that'll work for search results returning any number of granule records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:36:21.542075Z",
     "start_time": "2020-08-03T21:36:21.538269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.podaac.uat.earthdata.nasa.gov/podaac-uat-cumulus-protected/JASON-1_L2_OST_GPR_E/JA1_GPR_2PeP230_001_20080403_213355_20080403_223004.nc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloads = [r['umm']['RelatedUrls'][0]['URL'] for r in results['items']]\n",
    "downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T12:03:56.780074Z",
     "start_time": "2020-07-25T12:03:56.777273Z"
    }
   },
   "source": [
    "Finish by downloading the files to the data directory in a loop. Overwrite `.update` with a new timestamp on success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-03T21:36:23.391Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in downloads:\n",
    "    try:\n",
    "        urlretrieve(f, f\"{data}/{basename(f)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{datetime.now()}] FAILURE: {f}\\n\\n{e}\\n\")\n",
    "        raise e\n",
    "    else:\n",
    "        print(f\"[{datetime.now()}] SUCCESS: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were updates to the local time series during this run and no exceptions were raised during the download loop, then overwrite the timestamp file that tracks updates to the data folder (`resources/nrt/.update`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T18:13:19.701674Z",
     "start_time": "2020-07-28T18:13:19.698405Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(results['items'])>0:\n",
    "    with open(f\"{data}/.update\", \"w\") as f:\n",
    "        f.write(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.528px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
