{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Getting-Started\" data-toc-modified-id=\"Getting-Started-1\">Getting Started</a></span><ul class=\"toc-item\"><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-1.1\">Parameters</a></span></li><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.2\">Requirements</a></span><ul class=\"toc-item\"><li><span><a href=\"#Earthdata-Authentication\" data-toc-modified-id=\"Earthdata-Authentication-1.2.1\">Earthdata Authentication</a></span></li></ul></li></ul></li><li><span><a href=\"#Hands-off-workflow\" data-toc-modified-id=\"Hands-off-workflow-2\">Hands-off workflow</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Retrieve-a-new-granule-listing-from-CMR\" data-toc-modified-id=\"1.-Retrieve-a-new-granule-listing-from-CMR-2.1\">1. Retrieve a new granule listing from CMR</a></span></li><li><span><a href=\"#1.-Check-the-status-of-the-local-data-directory\" data-toc-modified-id=\"1.-Check-the-status-of-the-local-data-directory-2.2\">1. Check the status of the local <code>data</code> directory</a></span></li><li><span><a href=\"#3.-Reconcile-local-data-with-current-CMR-granules\" data-toc-modified-id=\"3.-Reconcile-local-data-with-current-CMR-granules-2.3\">3. Reconcile local <code>data</code> with current CMR granules</a></span></li><li><span><a href=\"#Finishing-up\" data-toc-modified-id=\"Finishing-up-2.4\">Finishing up</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Sentinel-6 Data\n",
    "\n",
    "This notebook shows a simple way to download granules using the [CMR Search API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html). \n",
    "\n",
    "> **User note:**\n",
    ">  The notebook actually points to a MODIS SST collection for now ([https://doi.org/10.5067/GHMDA-2PJ19](https://doi.org/10.5067/GHMDA-2PJ19)). It will work just the same for Sentinel-6.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "### Parameters\n",
    "\n",
    "This workflow/notebook can be used to download Sentinel-6 data granules using configurable CMR Search queries.\n",
    "\n",
    "The variables in the cell below determine the workflow behavior:\n",
    "\n",
    "* `params`: A dictionary of CMR Search API query parameters for the *granules* endpoint. \n",
    "  * May be passed to the notebook as a JSON string with [papermill](https://papermill.readthedocs.io). \n",
    "  * Read about the many granules search options in the [CMR Search API documentation](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)\n",
    "* `data`: The path to a local directory in which to download/maintain a copy of the NRT granule time series.\n",
    "* `cmr`: The domain of the target CMR instance, either `cmr.earthdata.nasa.gov` or `cmr.uat.earthdata.nasa.gov`.\n",
    "\n",
    "This dictionary covers most of the useful granule search options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.091448Z",
     "start_time": "2020-09-10T21:05:38.085976Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# This cell accepts parameters from command line with papermill: \n",
    "#  https://papermill.readthedocs.io\n",
    "#\n",
    "# These variables should be set before the first run, then they \n",
    "#  should be left alone. All subsequent runs expect the values \n",
    "#  for params, cmr, data to be unchanged. The mins value has no \n",
    "#  impact on subsequent runs.\n",
    "#\n",
    "\n",
    "params = {\n",
    "\n",
    "    # TARGET COLLECTION:\n",
    "    'ShortName': \"MODIS_T-JPL-L2P-v2019.0\",       # \"MODIS_T-JPL-L2P-v2019.0\"\n",
    "    'collection_concept_id': None,                # \"C1234724471-POCLOUD\"\n",
    "\n",
    "    # TEMPORAL COVERAGE (\"START,END\"):\n",
    "    'temporal': \"2019-01-01T00:00:00Z,2019-01-10T00:00:00Z\",\n",
    "\n",
    "    # CMR/INGEST EVENT:\n",
    "    'created_at': None,\n",
    "    'updated_since': None,\n",
    "    'production_date': None,\n",
    "    'revision_date': None,\n",
    "    \n",
    "    # ORBIT/ACQUISITION REFERENCE ID:\n",
    "    'orbit_number': None,\n",
    "    'equator_crossing_longitude': None,\n",
    "    'equator_crossing_date': None,\n",
    "    'day_night_flag': None,                       # \"day\"/\"night\"/\"unspecified\"\n",
    "    'cycle': None ,                               # 230\n",
    "    'passes[0][pass]': None,                      # 1\n",
    "    'passes[1][pass]': None,                      # 2\n",
    "    'passes[2][pass]': None,                      # 3\n",
    "\n",
    "    # SPATIAL COVERAGE: \n",
    "    'bounding_box': \"-150,55,-145,60\",            # \"-146.5,57.5,-146,58\"\n",
    "    'polygon': None,                              # \"10,10,30,10,30,20,10,20,10,10\"\n",
    "    'point': None,                                # \"100,20\"\n",
    "    'line': None,                                 # \"-0.37,-14.07,4.75,1.27,25.13,-15.51\"\n",
    "    'circle': None,                               # \"-87.629717,41.878112,1000\"\n",
    "    'shapefile': None,\n",
    "\n",
    "    # API BEHAVIOR (Prob leave these alone.)\n",
    "    \"scroll\": \"true\",\n",
    "    \"page_size\": 20,\n",
    "    \"sort_key\": \"-start_date\",\n",
    "\n",
    "}\n",
    "\n",
    "cmr = \"cmr.uat.earthdata.nasa.gov\"                # \"cmr.earthdata.nasa.gov\"\n",
    "\n",
    "data = \"resources/detailed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `data` is pointed at a nearby folder [`resources/comprehensive`](resources/comprehensive/) by default. You should change `data` to a suitable download path on your file system. An unlucky sequence of git commands could disappear that folder and its downloads if your not careful. Just change it.\n",
    "\n",
    "If replacement `params` were NOT provided from the command line (as a JSON string; read [papermill](#)), clean up the dictionary of defaults by dropping all fields filled by `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.189561Z",
     "start_time": "2020-09-10T21:05:38.182008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ShortName': 'MODIS_T-JPL-L2P-v2019.0',\n",
       " 'temporal': '2019-01-01T00:00:00Z,2019-01-10T00:00:00Z',\n",
       " 'bounding_box': '-150,55,-145,60',\n",
       " 'scroll': 'true',\n",
       " 'page_size': 20,\n",
       " 'sort_key': '-start_date'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {par: val for par, val in params.items() if val is not None}\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "All package imports are in the Python 3 standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.283395Z",
     "start_time": "2020-09-10T21:05:38.273146Z"
    }
   },
   "outputs": [],
   "source": [
    "from netrc import netrc\n",
    "from getpass import getpass\n",
    "from json import dumps, loads\n",
    "from os import makedirs\n",
    "from os.path import isdir, basename\n",
    "from datetime import datetime, timedelta\n",
    "from http.cookiejar import CookieJar\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.parse import urlencode\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Earthdata Authentication\n",
    "\n",
    "Before you beginning this tutorial, make sure you have an Earthdata account: [https://urs.earthdata.nasa.gov](https://urs.earthdata.nasa.gov) for the operations envionrment (most common) or [https://uat.urs.earthdata.nasa.gov](https://uat.urs.earthdata.nasa.gov) for the UAT environment. Accounts are free to create and take just a moment to set up.\n",
    "\n",
    "We need some boilerplate up front to log in to Earthdata Login.  The function below will allow Python\n",
    "scripts to log into any Earthdata Login application programmatically.  To avoid being prompted for\n",
    "credentials every time you run and also allow clients such as curl to log in, you can add the following\n",
    "to a `.netrc` (`_netrc` on Windows) file in your home directory:\n",
    "\n",
    "```\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login <your username>\n",
    "    password <your password>\n",
    "```\n",
    "\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating\n",
    "\"netrc access too permissive.\"\n",
    "\n",
    "`$ chmod 0600 ~/.netrc` \n",
    "\n",
    "*You'll need to authenticate using the netrc method when running from command line with [`papermill`](https://papermill.readthedocs.io/en/latest/). You can log in manually by executing the cell below when running in the notebook client in your browser.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.354831Z",
     "start_time": "2020-09-10T21:05:38.350302Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT (Harmony's current default)\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    try:\n",
    "        username, _, password = netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        password = getpass()\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate with either `uat.urs.earthdata.nasa.gov` or `urs.earthdata.nasa.gov` depending on which CMR instance was selected in the parameters cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.422195Z",
     "start_time": "2020-09-10T21:05:38.413933Z"
    }
   },
   "outputs": [],
   "source": [
    "if cmr == \"cmr.uat.earthdata.nasa.gov\":\n",
    "    setup_earthdata_login_auth('uat.urs.earthdata.nasa.gov')\n",
    "elif cmr == \"cmr.earthdata.nasa.gov\":\n",
    "    setup_earthdata_login_auth('urs.earthdata.nasa.gov')\n",
    "else:\n",
    "    raise Exception(f\"ERROR: The CMR base url is invalid ({cmr})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-off workflow\n",
    "\n",
    "### 1. Retrieve a new granule listing from CMR\n",
    "\n",
    "Get the query parameters as a string and then the complete search url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:38.486351Z",
     "start_time": "2020-09-10T21:05:38.483847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cmr.uat.earthdata.nasa.gov/search/granules.umm_json?ShortName=MODIS_T-JPL-L2P-v2019.0&temporal=2019-01-01T00%3A00%3A00Z%2C2019-01-10T00%3A00%3A00Z&bounding_box=-150%2C55%2C-145%2C60&scroll=true&page_size=20&sort_key=-start_date\n"
     ]
    }
   ],
   "source": [
    "query = urlencode(params)\n",
    "url = f\"https://{cmr}/search/granules.umm_json?{query}\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:39.442718Z",
     "start_time": "2020-09-10T21:05:38.487974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status after one request: (20/100)\n"
     ]
    }
   ],
   "source": [
    "with request.urlopen(url) as response:\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")  # Record the time of the request.\n",
    "    try:\n",
    "        results = loads(response.read().decode())                 # Read-Decode-Load results from JSON.\n",
    "        scroll = response.getheader(\"Cmr-Scroll-Id\")              # Get response header for 'Cmr-Scroll-Id'.\n",
    "    except (HTTPError, URLError) as e:\n",
    "        raise e\n",
    "    else:\n",
    "        req = request.Request(url, headers={'Client-Id': \"S6\", 'CMR-Scroll-Id': scroll})\n",
    "\n",
    "print(f\"Status after one request: ({len(results['items'])}/{results['hits']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit as many requests as needed to get all the target granule records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.651066Z",
     "start_time": "2020-09-10T21:05:39.445263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status after request loop: (100/100)\n"
     ]
    }
   ],
   "source": [
    "while int(results['hits'])!=len(results['items']):\n",
    "    try:\n",
    "        with request.urlopen(req) as response:\n",
    "            aresults = loads(response.read().decode())\n",
    "    except (HTTPError, URLError) as e:\n",
    "        raise e\n",
    "    else:\n",
    "        try:\n",
    "            results['items'].extend(aresults['items'])\n",
    "        except KeyError as e:\n",
    "            break\n",
    "\n",
    "print(f\"Status after request loop: ({len(results['items'])}/{results['hits']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neatly print the `RelatedUrls` field of the first granule record (if at least one was returned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.657290Z",
     "start_time": "2020-09-10T21:05:41.653888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"URL\": \"https://archive.podaac.uat.earthdata.nasa.gov/podaac-uat-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190109213501-JPL-L2P_GHRSST-SSTskin-MODIS_T-N-v02.0-fv01.0.nc\",\n",
      "    \"Type\": \"GET DATA\",\n",
      "    \"Description\": \"The base directory location for the granule.\"\n",
      "  },\n",
      "  {\n",
      "    \"URL\": \"https://archive.podaac.uat.earthdata.nasa.gov/podaac-uat-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190109213501-JPL-L2P_GHRSST-SSTskin-MODIS_T-N-v02.0-fv01.0.cmr.json\",\n",
      "    \"Type\": \"EXTENDED METADATA\",\n",
      "    \"Description\": \"File to download\"\n",
      "  },\n",
      "  {\n",
      "    \"URL\": \"https://archive.podaac.uat.earthdata.nasa.gov/s3credentials\",\n",
      "    \"Type\": \"VIEW RELATED INFORMATION\",\n",
      "    \"Description\": \"api endpoint to retrieve temporary credentials valid for same-region direct s3 access\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "if len(results['items']) >= 1:\n",
    "    print(dumps(results['items'][0]['umm']['RelatedUrls'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check the status of the local `data` directory\n",
    "\n",
    "The target directory for our granule downloads is defined by the `data` variable.\n",
    "\n",
    "Make the output directory at the path given by `data`, if it doesn't already exist. If it *does* exist, look for a file `.history` inside and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.664338Z",
     "start_time": "2020-09-10T21:05:41.659048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:\tTarget `data` directory already exists (resources/detailed)\n",
      "info:\tThere are currently '100' granules in local `data`.\n"
     ]
    }
   ],
   "source": [
    "history_file = join(data, \".history\")\n",
    "history_data = {}\n",
    "\n",
    "if not isdir(data):\n",
    "    print(f\"info:\\tCreate the target `data` directory ({data})\")\n",
    "    makedirs(data)\n",
    "else:\n",
    "    print(f\"info:\\tTarget `data` directory already exists ({data})\")\n",
    "    if not isfile(history_file):\n",
    "        print(f\"warn:\\tNo history file found in data directory ({history_file})\")\n",
    "    else:\n",
    "        with open(history_file, \"r\") as f:\n",
    "            history_data = load(f)\n",
    "        print(f\"info:\\tThere are currently '{len(history_data)}' granules in local `data`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reconcile local `data` with current CMR granules\n",
    "\n",
    "We'll iterate over the granules records returned by our most recent search(es) and download all the new ones that weren't downloaded during previous runs. If they *WERE downloaded in previous runs*, we'll download the latest version ('revision', technically) and overwrite them.\n",
    "\n",
    "We'll track all changes into perpetuity using the `.history` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.713700Z",
     "start_time": "2020-09-10T21:05:41.665985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: |-------------------------------------------------------| 1 / 100 (1.0%)\r",
      "\r",
      "Progress: |#------------------------------------------------------| 2 / 100 (2.0%)\r",
      "\r",
      "Progress: |#------------------------------------------------------| 3 / 100 (3.0%)\r",
      "\r",
      "Progress: |##-----------------------------------------------------| 4 / 100 (4.0%)\r",
      "\r",
      "Progress: |##-----------------------------------------------------| 5 / 100 (5.0%)\r",
      "\r",
      "Progress: |###----------------------------------------------------| 6 / 100 (6.0%)\r",
      "\r",
      "Progress: |###----------------------------------------------------| 7 / 100 (7.0%)\r",
      "\r",
      "Progress: |####---------------------------------------------------| 8 / 100 (8.0%)\r",
      "\r",
      "Progress: |####---------------------------------------------------| 9 / 100 (9.0%)\r",
      "\r",
      "Progress: |#####--------------------------------------------------| 10 / 100 (10.0%)\r",
      "\r",
      "Progress: |######-------------------------------------------------| 11 / 100 (11.0%)\r",
      "\r",
      "Progress: |######-------------------------------------------------| 12 / 100 (12.0%)\r",
      "\r",
      "Progress: |#######------------------------------------------------| 13 / 100 (13.0%)\r",
      "\r",
      "Progress: |#######------------------------------------------------| 14 / 100 (14.0%)\r",
      "\r",
      "Progress: |########-----------------------------------------------| 15 / 100 (15.0%)\r",
      "\r",
      "Progress: |########-----------------------------------------------| 16 / 100 (16.0%)\r",
      "\r",
      "Progress: |#########----------------------------------------------| 17 / 100 (17.0%)\r",
      "\r",
      "Progress: |#########----------------------------------------------| 18 / 100 (18.0%)\r",
      "\r",
      "Progress: |##########---------------------------------------------| 19 / 100 (19.0%)\r",
      "\r",
      "Progress: |###########--------------------------------------------| 20 / 100 (20.0%)\r",
      "\r",
      "Progress: |###########--------------------------------------------| 21 / 100 (21.0%)\r",
      "\r",
      "Progress: |############-------------------------------------------| 22 / 100 (22.0%)\r",
      "\r",
      "Progress: |############-------------------------------------------| 23 / 100 (23.0%)\r",
      "\r",
      "Progress: |#############------------------------------------------| 24 / 100 (24.0%)\r",
      "\r",
      "Progress: |#############------------------------------------------| 25 / 100 (25.0%)\r",
      "\r",
      "Progress: |##############-----------------------------------------| 26 / 100 (26.0%)\r",
      "\r",
      "Progress: |##############-----------------------------------------| 27 / 100 (27.0%)\r",
      "\r",
      "Progress: |###############----------------------------------------| 28 / 100 (28.0%)\r",
      "\r",
      "Progress: |###############----------------------------------------| 29 / 100 (29.0%)\r",
      "\r",
      "Progress: |################---------------------------------------| 30 / 100 (30.0%)\r",
      "\r",
      "Progress: |#################--------------------------------------| 31 / 100 (31.0%)\r",
      "\r",
      "Progress: |#################--------------------------------------| 32 / 100 (32.0%)\r",
      "\r",
      "Progress: |##################-------------------------------------| 33 / 100 (33.0%)\r",
      "\r",
      "Progress: |##################-------------------------------------| 34 / 100 (34.0%)\r",
      "\r",
      "Progress: |###################------------------------------------| 35 / 100 (35.0%)\r",
      "\r",
      "Progress: |###################------------------------------------| 36 / 100 (36.0%)\r",
      "\r",
      "Progress: |####################-----------------------------------| 37 / 100 (37.0%)\r",
      "\r",
      "Progress: |####################-----------------------------------| 38 / 100 (38.0%)\r",
      "\r",
      "Progress: |#####################----------------------------------| 39 / 100 (39.0%)\r",
      "\r",
      "Progress: |######################---------------------------------| 40 / 100 (40.0%)\r",
      "\r",
      "Progress: |######################---------------------------------| 41 / 100 (41.0%)\r",
      "\r",
      "Progress: |#######################--------------------------------| 42 / 100 (42.0%)\r",
      "\r",
      "Progress: |#######################--------------------------------| 43 / 100 (43.0%)\r",
      "\r",
      "Progress: |########################-------------------------------| 44 / 100 (44.0%)\r",
      "\r",
      "Progress: |########################-------------------------------| 45 / 100 (45.0%)\r",
      "\r",
      "Progress: |#########################------------------------------| 46 / 100 (46.0%)\r",
      "\r",
      "Progress: |#########################------------------------------| 47 / 100 (47.0%)\r",
      "\r",
      "Progress: |##########################-----------------------------| 48 / 100 (48.0%)\r",
      "\r",
      "Progress: |##########################-----------------------------| 49 / 100 (49.0%)\r",
      "\r",
      "Progress: |###########################----------------------------| 50 / 100 (50.0%)\r",
      "\r",
      "Progress: |############################---------------------------| 51 / 100 (51.0%)\r",
      "\r",
      "Progress: |############################---------------------------| 52 / 100 (52.0%)\r",
      "\r",
      "Progress: |#############################--------------------------| 53 / 100 (53.0%)\r",
      "\r",
      "Progress: |#############################--------------------------| 54 / 100 (54.0%)\r",
      "\r",
      "Progress: |##############################-------------------------| 55 / 100 (55.0%)\r",
      "\r",
      "Progress: |##############################-------------------------| 56 / 100 (56.0%)\r",
      "\r",
      "Progress: |###############################------------------------| 57 / 100 (57.0%)\r",
      "\r",
      "Progress: |###############################------------------------| 58 / 100 (58.0%)\r",
      "\r",
      "Progress: |################################-----------------------| 59 / 100 (59.0%)\r",
      "\r",
      "Progress: |#################################----------------------| 60 / 100 (60.0%)\r",
      "\r",
      "Progress: |#################################----------------------| 61 / 100 (61.0%)\r",
      "\r",
      "Progress: |##################################---------------------| 62 / 100 (62.0%)\r",
      "\r",
      "Progress: |##################################---------------------| 63 / 100 (63.0%)\r",
      "\r",
      "Progress: |###################################--------------------| 64 / 100 (64.0%)\r",
      "\r",
      "Progress: |###################################--------------------| 65 / 100 (65.0%)\r",
      "\r",
      "Progress: |####################################-------------------| 66 / 100 (66.0%)\r",
      "\r",
      "Progress: |####################################-------------------| 67 / 100 (67.0%)\r",
      "\r",
      "Progress: |#####################################------------------| 68 / 100 (68.0%)\r",
      "\r",
      "Progress: |#####################################------------------| 69 / 100 (69.0%)\r",
      "\r",
      "Progress: |######################################-----------------| 70 / 100 (70.0%)\r",
      "\r",
      "Progress: |#######################################----------------| 71 / 100 (71.0%)\r",
      "\r",
      "Progress: |#######################################----------------| 72 / 100 (72.0%)\r",
      "\r",
      "Progress: |########################################---------------| 73 / 100 (73.0%)\r",
      "\r",
      "Progress: |########################################---------------| 74 / 100 (74.0%)\r",
      "\r",
      "Progress: |#########################################--------------| 75 / 100 (75.0%)\r",
      "\r",
      "Progress: |#########################################--------------| 76 / 100 (76.0%)\r",
      "\r",
      "Progress: |##########################################-------------| 77 / 100 (77.0%)\r",
      "\r",
      "Progress: |##########################################-------------| 78 / 100 (78.0%)\r",
      "\r",
      "Progress: |###########################################------------| 79 / 100 (79.0%)\r",
      "\r",
      "Progress: |############################################-----------| 80 / 100 (80.0%)\r",
      "\r",
      "Progress: |############################################-----------| 81 / 100 (81.0%)\r",
      "\r",
      "Progress: |#############################################----------| 82 / 100 (82.0%)\r",
      "\r",
      "Progress: |#############################################----------| 83 / 100 (83.0%)\r",
      "\r",
      "Progress: |##############################################---------| 84 / 100 (84.0%)\r",
      "\r",
      "Progress: |##############################################---------| 85 / 100 (85.0%)\r",
      "\r",
      "Progress: |###############################################--------| 86 / 100 (86.0%)\r",
      "\r",
      "Progress: |###############################################--------| 87 / 100 (87.0%)\r",
      "\r",
      "Progress: |################################################-------| 88 / 100 (88.0%)\r",
      "\r",
      "Progress: |################################################-------| 89 / 100 (89.0%)\r",
      "\r",
      "Progress: |#################################################------| 90 / 100 (90.0%)\r",
      "\r",
      "Progress: |##################################################-----| 91 / 100 (91.0%)\r",
      "\r",
      "Progress: |##################################################-----| 92 / 100 (92.0%)\r",
      "\r",
      "Progress: |###################################################----| 93 / 100 (93.0%)\r",
      "\r",
      "Progress: |###################################################----| 94 / 100 (94.0%)\r",
      "\r",
      "Progress: |####################################################---| 95 / 100 (95.0%)\r",
      "\r",
      "Progress: |####################################################---| 96 / 100 (96.0%)\r",
      "\r",
      "Progress: |#####################################################--| 97 / 100 (97.0%)\r",
      "\r",
      "Progress: |#####################################################--| 98 / 100 (98.0%)\r",
      "\r",
      "Progress: |######################################################-| 99 / 100 (99.0%)\r",
      "\r",
      "Progress: |#######################################################| 100 / 100 (100.0%)\r\n"
     ]
    }
   ],
   "source": [
    "def progress_bar(i: int, n: int):\n",
    "    \"\"\"Hideous function that produces a nice ASCII progress bar.\"\"\"\n",
    "    F, P = int(55*i//n), (\"{0:.\"+str(1)+\"f}\").format(100*(i/float(n)))\n",
    "    print(f'\\rProgress: |{\"#\"*F+\"-\"*(55-F)}| {i} / {n} ({P}%)', end='\\r')\n",
    "    if i == n:\n",
    "        print()\n",
    "\n",
    "\n",
    "for i, granule in enumerate(results['items']):\n",
    "\n",
    "    # Get a timestamp marking the start of this potential granule download.\n",
    "    time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    \n",
    "    # Print a simple ASCII progress bar to notify user of the current status.\n",
    "    progress_bar(i+1, len(results['items']))\n",
    "    \n",
    "    # Select CMR Search and UMM metadata for the current granule (dicts).\n",
    "    meta, umm = list(granule.values())\n",
    "    \n",
    "    # Get the granule's unique 'native-id' from the CMR Search metadata.\n",
    "    nativeid, https, opendap = meta['native-id'], None, None\n",
    "\n",
    "    # Loop over the \"RelatedUrls\" until access urls are identified.\n",
    "    for ru in umm['RelatedUrls']:\n",
    "        if ru['Type'] == \"GET DATA\":\n",
    "            https = ru['URL']\n",
    "        if \"opendap\" in (ru['URL']+ru['Description']).lower():\n",
    "            opendap = ru['URL'].replace(\".html\",\"\")\n",
    "    \n",
    "    # Get the 'native-id' of the current granule.\n",
    "    nativeid = meta['native-id']\n",
    "    \n",
    "    # Print a warning if an HTTPS url was not found.\n",
    "    if https is None:\n",
    "        print(f\"[{time}] warn: no HTTPS download for '{nativeid}'.\\n\")\n",
    "        continue\n",
    "\n",
    "    # 1. Is the granule referenced in the history file?\n",
    "    if nativeid in list(history_data.keys()):\n",
    "        # 2. Is some version of the granule already in the data directory?\n",
    "        if basename(https) in listdir(data):\n",
    "            # 3. Is the old 'revision-id' the same as the one in CMR?\n",
    "            if meta['revision-id']==history_data[nativeid]['revision-id']:\n",
    "                continue  # If all three are True, skip the download.\n",
    "    try:\n",
    "        # Attempt the download if satisfied all conditions above.\n",
    "        request.urlretrieve(https, f\"{data}/{basename(https)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{time}] warn: HTTPS download failure for '{nativeid}'.\\n\")\n",
    "        raise e\n",
    "\n",
    "    # Replace the entry in the history dictionary to reflect new granule.\n",
    "    history_data[nativeid] = {**meta, 'https': https, 'opendap': opendap, 'recon': time}\n",
    "\n",
    "    # Dump the history file to overwrite the old one, capturing this successful download.\n",
    "    with open(history_file, \"w\") as f:\n",
    "        f.write(dumps(history_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing up\n",
    "\n",
    "Now read the history file back into a Python dictionary, print its size (item count) and its first item for the user's reference. We're storing:\n",
    "\n",
    "* the CMR Search metadata (key pattern: `results['items'][#]['meta']`),\n",
    "* the access urls from the UMM metadata (key pattern: `results['items'][#]['umm']['RelatedUrls']`),\n",
    "* a timestamp indicating the time the granule was last downloaded/updated locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.719482Z",
     "start_time": "2020-09-10T21:05:41.716139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 100\n"
     ]
    }
   ],
   "source": [
    "with open(history_file, \"r\") as f:\n",
    "    history_data = load(f)\n",
    "\n",
    "print(f\"Count: {len(history_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T21:05:41.723614Z",
     "start_time": "2020-09-10T21:05:41.721012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"concept-type\": \"granule\",\n",
      "  \"concept-id\": \"G1235913051-POCLOUD\",\n",
      "  \"revision-id\": 1,\n",
      "  \"native-id\": \"20190109213501-JPL-L2P_GHRSST-SSTskin-MODIS_T-N-v02.0-fv01.0\",\n",
      "  \"provider-id\": \"POCLOUD\",\n",
      "  \"format\": \"application/vnd.nasa.cmr.umm+json\",\n",
      "  \"revision-date\": \"2020-07-04T08:44:56.751Z\",\n",
      "  \"https\": \"https://archive.podaac.uat.earthdata.nasa.gov/podaac-uat-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190109213501-JPL-L2P_GHRSST-SSTskin-MODIS_T-N-v02.0-fv01.0.nc\",\n",
      "  \"opendap\": null,\n",
      "  \"recon\": \"2020-09-10T16:36:16Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dumps(list(history_data.items())[0][1], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.528px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
